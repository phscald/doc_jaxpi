
I0523 13:59:07.019582 124534130061312 train.py:234] Training time window 1
Waiting for JIT...
Traceback (most recent call last):
  File "/home/pedro/PINN/jaxpi/examples/ns_unsteady_cylinder/main.py", line 39, in <module>
    app.run(main)
  File "/usr/local/lib/python3.11/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.11/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
             ^^^^^^^^^^
  File "/home/pedro/PINN/jaxpi/examples/ns_unsteady_cylinder/main.py", line 31, in main
    train.train_and_evaluate(FLAGS.config, FLAGS.workdir)
  File "/home/pedro/PINN/jaxpi/examples/ns_unsteady_cylinder/train.py", line 290, in train_and_evaluate
    model = train_one_window(config, workdir, model, samplers, idx)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pedro/PINN/jaxpi/examples/ns_unsteady_cylinder/train.py", line 132, in train_one_window
    model.state = model.update_weights(model.state, batch)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 24008215808 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:    4.33MiB
              constant allocation:     1.1KiB
        maybe_live_out allocation:    4.13MiB
     preallocated temp allocation:   22.36GiB
  preallocated temp fragmentation:  210.80MiB (0.92%)
                 total allocation:   22.37GiB
              total fragmentation:  210.90MiB (0.92%)
Peak buffers:
	Buffer 1:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 2:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 3:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 4:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 5:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 6:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 7:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(transpose(vmap(jvp(jvp(ModifiedMlp)))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 8:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/Dense_5/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=121 deduplicated_name="gemm_fusion_dot.3040.0"
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 9:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 10:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 11:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 12:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 13:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/add_any" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=188
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 14:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(jvp(transpose(vmap(jvp(jvp(ModifiedMlp))))))/Dense_4/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=121 deduplicated_name="gemm_fusion_dot.3040.0"
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
	Buffer 15:
		Size: 90.00MiB
		Operator: op_name="pmap(update_weights)/jit(main)/jit(compute_weights)/vmap(transpose(jvp(jit(losses))))/jit(res_and_w)/vmap(ModifiedMlp)/Dense_6/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/usr/local/lib/python3.11/dist-packages/jaxpi/archs.py" source_line=121
		XLA Label: fusion
		Shape: f32[12,240,8192]
		==========================
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.